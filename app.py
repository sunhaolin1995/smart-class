import streamlit as st
import os
from docx import Document
from docx.shared import Pt
import json
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from io import BytesIO

# --- Configuration ---
st.set_page_config(page_title="AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨", layout="wide")

# --- Helper Functions ---

def get_table_structure(doc):
    """
    Traverses all tables in the document to map "Keys" (labels) to "Targets" (empty cells).
    Returns a list of binding objects:
    {
        'key_text': str,
        'key_coords': (table_idx, row_idx, col_idx),
        'target_coords': (table_idx, row_idx, col_idx)
    }
    """
    structure = []
    
    for t_idx, table in enumerate(doc.tables):
        rows = len(table.rows)
        cols = len(table.columns)
        
        # We process cells to find "Label -> Empty Cell" relationships.
        # Simple Heuristic: 
        # 1. Look Right: If cell(r, c) has text and cell(r, c+1) is empty, map them.
        # 2. Look Down: If cell(r, c) has text and cell(r+1, c) is empty (and right wasn't a match), map them.
        
        processed_targets = set()

        for r in range(rows):
            for c in range(cols):
                try:
                    cell = table.cell(r, c)
                    text = cell.text.strip()
                    
                    if not text:
                        continue # Skip empty key cells
                    
                    # Potential Key found: `text`
                    
                    key_coords = (t_idx, r, c)
                    target_coords = None
                    
                    # Strategy 1: Look Right
                    if c + 1 < cols:
                        right_cell = table.cell(r, c + 1)
                        if not right_cell.text.strip() and (t_idx, r, c+1) not in processed_targets:
                            target_coords = (t_idx, r, c + 1)
                    
                    # Strategy 2: Look Down (only if Right didn't work)
                    if target_coords is None and r + 1 < rows:
                         down_cell = table.cell(r + 1, c)
                         if not down_cell.text.strip() and (t_idx, r+1, c) not in processed_targets:
                             target_coords = (t_idx, r + 1, c)

                    if target_coords:
                        structure.append({
                            'key_text': text,
                            'key_coords': key_coords,
                            'target_coords': target_coords
                        })
                        processed_targets.add(target_coords)
                        
                except IndexError:
                    continue
                    
    return structure

def generate_ai_content(user_inputs, doc_keys, api_key):
    """
    Uses LangChain to map user inputs to document keys and generate missing content.
    """
    if not api_key:
        st.error("è¯·è¾“å…¥ OpenAI API Key")
        return {}

    llm = ChatOpenAI(
        model="deepseek-chat", 
        temperature=0.7,
        base_url="https://api.deepseek.com",
        openai_api_key=api_key
    )

    # Convert keys to a clean list of strings
    keys_list = [item['key_text'] for item in doc_keys]
    
    # Prompt Design
    system_prompt = """
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™æ¡ˆç¼–å†™åŠ©æ‰‹ã€‚
    ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·æä¾›çš„ã€è¡¨å•ä¿¡æ¯ã€‘å¡«å…¥åˆ°ã€æ–‡æ¡£ç»“æž„åˆ—è¡¨ã€‘ä¸­ã€‚
    
    è§„åˆ™ï¼š
    1. å¦‚æžœã€æ–‡æ¡£ç»“æž„åˆ—è¡¨ã€‘ä¸­çš„å­—æ®µåœ¨ã€è¡¨å•ä¿¡æ¯ã€‘ä¸­æœ‰ç›´æŽ¥å¯¹åº”ï¼ˆå¦‚å§“åã€è¯¾ç¨‹åï¼‰ï¼Œç›´æŽ¥å¡«å…¥ã€‚
    2. å¦‚æžœéœ€è¦ç”Ÿæˆå†…å®¹ï¼ˆå¦‚â€œæ•™å­¦ç›®æ ‡â€ã€â€œå­¦æƒ…åˆ†æžâ€ï¼‰ï¼Œè¯·æ ¹æ®ã€è¡¨å•ä¿¡æ¯ã€‘ä¸­çš„â€œè¯¾ç¨‹å¤§çº²/ä¸»é¢˜â€è¿›è¡Œä¸“ä¸šæ‰©å†™ã€‚
    3. å¦‚æžœæŸä¸ªå­—æ®µæ— æ³•ç”Ÿæˆä¸”æ— ä¿¡æ¯ï¼Œå¡«å…¥ "ï¼ˆç©ºï¼‰" æˆ–ç•™ç™½ã€‚
    4. è¾“å‡ºå¿…é¡»æ˜¯ JSON æ ¼å¼ï¼š {{ "æ–‡æ¡£å­—æ®µå": "å¡«å…¥å†…å®¹" }}
    """
    
    human_template = """
    ã€è¡¨å•ä¿¡æ¯ã€‘: {user_inputs}
    
    ã€æ–‡æ¡£ç»“æž„åˆ—è¡¨ã€‘: {keys_list}
    
    è¯·è¾“å‡º JSON æ˜ å°„ç»“æžœã€‚
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", human_template)
    ])
    
    chain = prompt | llm
    
    try:
        response = chain.invoke({
            "user_inputs": json.dumps(user_inputs, ensure_ascii=False),
            "keys_list": json.dumps(keys_list, ensure_ascii=False)
        })
        
        # Parse JSON from content (Found robustly)
        content = response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        return json.loads(content)
        
    except Exception as e:
        st.error(f"AI ç”Ÿæˆå¤±è´¥: {e}")
        return {}

def set_cell_text_preserving_style(cell, text):
    """
    Sets text in a cell while attempting to preserve the style of the first paragraph/run.
    """
    if not cell.paragraphs:
        cell.add_paragraph(text)
        return

    paragraph = cell.paragraphs[0]
    
    # Check if there's existing style/runs to copy
    style_run = None
    if paragraph.runs:
        style_run = paragraph.runs[0]
    
    # Clear existing content but keep the paragraph object
    paragraph.clear()
    
    # Add new run
    run = paragraph.add_run(text)
    
    # Copy basic styles if they existed
    if style_run:
        run.bold = style_run.bold
        run.italic = style_run.italic
        run.font.name = style_run.font.name
        if style_run.font.size:
            run.font.size = style_run.font.size
            
    # Fallback: Try to ensure Chinese font compatibility if needed (Optional)
    # run.font.element.rPr.rFonts.setall(qn('w:eastAsia'), 'SimSun') 

# --- Main App Interface ---

def main():
    st.title("ðŸ“š AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (DeepSeek ç‰ˆ)")
    st.markdown("ä¸Šä¼ ä»»æ„ Word è¡¨æ ¼æ¨¡æ¿ï¼ŒAI è‡ªåŠ¨è¯†åˆ«å­—æ®µå¹¶å¡«å…¥æ•™æ¡ˆå†…å®¹ã€‚")

    with st.sidebar:
        st.header("1. é…ç½®ä¸Žè¾“å…¥")
        api_key = st.text_input("DeepSeek API Key", type="password")
        
        st.subheader("åŸºæœ¬ä¿¡æ¯")
        dept = st.text_input("éƒ¨é—¨/é™¢ç³»", "ä¿¡æ¯å·¥ç¨‹å­¦é™¢")
        teacher = st.text_input("æ•™å¸ˆå§“å", "å¼ ä¸‰")
        course = st.text_input("è¯¾ç¨‹åç§°", "Python ç¨‹åºè®¾è®¡")
        cls = st.text_input("ç­çº§", "23çº§è®¡ç®—æœº1ç­")
        time = st.text_input("æŽˆè¯¾æ—¶é—´", "2024-03-20")
        location = st.text_input("æŽˆè¯¾åœ°ç‚¹", "A305")
        
        st.subheader("æ ¸å¿ƒå†…å®¹")
        topic_outline = st.text_area("æœ¬èŠ‚è¯¾ä¸»é¢˜ä¸Žå¤§çº²", height=200, 
                                     placeholder="ä¾‹å¦‚ï¼š\nä¸»é¢˜ï¼šPython å¾ªçŽ¯ç»“æž„\n1. while å¾ªçŽ¯è¯­æ³•\n2. for å¾ªçŽ¯è¯­æ³•\n3. break ä¸Ž continue\n4. å®žæˆ˜æ¡ˆä¾‹ï¼šçŒœæ•°å­—æ¸¸æˆ")
        
        user_inputs = {
            "éƒ¨é—¨": dept,
            "æ•™å¸ˆå§“å": teacher,
            "è¯¾ç¨‹åç§°": course,
            "ç­çº§": cls,
            "æ—¶é—´": time,
            "åœ°ç‚¹": location,
            "è¯¾ç¨‹å¤§çº²": topic_outline
        }

    # Main Area
    uploaded_file = st.file_uploader("ä¸Šä¼  Word æ•™æ¡ˆæ¨¡æ¿ (.docx)", type=["docx"])

    if uploaded_file and st.button("å¼€å§‹ç”Ÿæˆ"):
        if not api_key:
            st.warning("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Key")
            return

        with st.spinner("1/3 æ­£åœ¨è§£æžæ–‡æ¡£ç»“æž„..."):
            # Load doc
            doc = Document(uploaded_file)
            structure = get_table_structure(doc)
            
            if not structure:
                st.error("æœªåœ¨æ–‡æ¡£ä¸­æ£€æµ‹åˆ°æœ‰æ•ˆçš„è¡¨æ ¼ç»“æž„ï¼Œè¯·æ£€æŸ¥æ¨¡æ¿ã€‚")
                return
            
            # Show preview of detected keys (optional debugging)
            # st.write(f"æ£€æµ‹åˆ° {len(structure)} ä¸ªå¡«ç©ºé¡¹: {[s['key_text'] for s in structure]}")

        with st.spinner("2/3 AI æ­£åœ¨ç”Ÿæˆæ•™æ¡ˆå†…å®¹..."):
            # Generate content
            mapping_result = generate_ai_content(user_inputs, structure, api_key)
            if not mapping_result:
                st.stop()

        with st.spinner("3/3 æ­£åœ¨å†™å…¥æ–‡æ¡£..."):
            # Fill content
            fill_count = 0
            for item in structure:
                key = item['key_text']
                target_coords = item['target_coords']
                
                # Fuzzy get (in case keys slightly mismatch or AI shortened them)
                # Here we assume exact match from the JSON Key to parsed Key
                content = mapping_result.get(key)
                
                if content:
                    t_idx, r, c = target_coords
                    target_cell = doc.tables[t_idx].cell(r, c)
                    set_cell_text_preserving_style(target_cell, str(content))
                    fill_count += 1
            
            st.success(f"ç”Ÿæˆå®Œæˆï¼å·²å¡«å…… {fill_count} ä¸ªæ•°æ®é¡¹ã€‚")
            
            # Save to buffer
            buffer = BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            
            st.download_button(
                label="ä¸‹è½½ç”Ÿæˆçš„æ•™æ¡ˆ",
                data=buffer,
                file_name="generated_lesson_plan.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )

if __name__ == "__main__":
    main()
