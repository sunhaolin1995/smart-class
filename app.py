import streamlit as st
import os
from docx import Document
from docx.shared import Pt
import json
import time
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from io import BytesIO

# --- Configuration ---
st.set_page_config(page_title="AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (V2 Pro)", layout="wide", initial_sidebar_state="expanded")

# --- UI Components: Console Logger ---
class ConsoleLogger:
    def __init__(self):
        self.container = st.empty()
        self.logs = []

    def log(self, message, icon="ğŸ¤–"):
        timestamp = time.strftime("%H:%M:%S")
        self.logs.append(f"`{timestamp}` {icon} {message}")
        with self.container.container():
            with st.expander("ğŸ–¥ï¸ AI è¿è¡Œç»ˆç«¯ (å®æ—¶æ—¥å¿—)", expanded=True):
                for log in self.logs[-5:]: # Show last 5 logs
                    st.markdown(log)
    
    def clear(self):
        self.container.empty()
        self.logs = []

# --- Logic: Smart Parsing V2 ---
def get_cell_text(cell):
    return cell.text.strip()

def look_around_for_context(table, r, c):
    """
    å‘ä¸Š/å‘å·¦æŸ¥æ‰¾ï¼Œä¸ºé€šç”¨æ ‡é¢˜å¯»æ‰¾â€œçˆ¶çº§ä¸Šä¸‹æ–‡â€ã€‚
    ç¤ºä¾‹ï¼šå¦‚æœå•å…ƒæ ¼æ˜¯â€œå†…å®¹â€ï¼ˆé€šç”¨è¯ï¼‰ï¼Œå‘å·¦æŸ¥æ‰¾çœ‹åˆ°â€œè¯¾å‰â€ã€‚
    è¿”å›ï¼šâ€œä¸Šä¸‹æ–‡ > å•å…ƒæ ¼æ–‡æœ¬â€ æˆ– ä»…â€œå•å…ƒæ ¼æ–‡æœ¬â€
    """
    current_text = get_cell_text(table.cell(r, c))
    
    # 1. å‘å·¦æŸ¥æ‰¾ (åŒä¸€è¡Œ, c-1)
    if c > 0:
        left_text = get_cell_text(table.cell(r, c - 1))
        if left_text:
            return f"{left_text} > {current_text}"
            
    # 2. å‘ä¸ŠæŸ¥æ‰¾ (r-1, åŒä¸€åˆ—) - ä¸»è¦ç”¨äºå‚ç›´åˆå¹¶çš„å•å…ƒæ ¼
    if r > 0:
        up_text = get_cell_text(table.cell(r - 1, c))
        # ä»…å½“ä¸Šæ–¹æ–‡æœ¬æ˜¯è§†è§‰åˆå¹¶æˆ–ç›¸å…³æ—¶ä½¿ç”¨ (å¯å‘å¼)
        # å¦‚æœæ²¡æœ‰ç¡®åˆ‡çš„åˆå¹¶ä¿¡æ¯ï¼Œè¿™æ¯”è¾ƒæ£˜æ‰‹ï¼Œä½†æˆ‘ä»¬å¯ä»¥å°è¯•
        if up_text and up_text != current_text:
             return f"{up_text} > {current_text}"
    
    return current_text

def get_table_structure_v2(doc, logger=None):
    """
    V2 è§£æå™¨ï¼šéå†æ‰€æœ‰è¡¨æ ¼ï¼Œè¯†åˆ« Keyï¼ˆå­—æ®µåï¼‰ä¸ Targetï¼ˆå¡«ç©ºä½ç½®ï¼‰ã€‚
    é’ˆå¯¹ "æ•™å­¦è¿‡ç¨‹" ç­‰å¤æ‚è¡¨æ ¼ï¼Œå¢å¼ºäº†ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ› (å‘å·¦/å‘ä¸ŠæŸ¥æ‰¾)ã€‚
    """
    if logger: logger.log("å¼€å§‹æ‰«ææ–‡æ¡£ç»“æ„...", "ğŸ“„")
    
    structure = []
    
    for t_idx, table in enumerate(doc.tables):
        rows = len(table.rows)
        cols = len(table.columns)
        
        processed_targets = set()

        for r in range(rows):
            for c in range(cols):
                try:
                    cell = table.cell(r, c)
                    text = cell.text.strip()
                    
                    if not text:
                        continue # è·³è¿‡ç©ºçš„ Key å•å…ƒæ ¼
                    
                    # æ™ºèƒ½ä¸Šä¸‹æ–‡ Key
                    # å¦‚æœæ–‡æœ¬å¾ˆçŸ­/å¾ˆé€šç”¨ (å¦‚ "å†…å®¹", "æ—¶é—´")ï¼Œå°è¯•è¿½åŠ ä¸Šä¸‹æ–‡
                    full_key = text
                    if len(text) < 4 or text in ["å†…å®¹", "å­¦ç”Ÿæ´»åŠ¨", "æ•™å¸ˆæ´»åŠ¨", "è®¾è®¡æ„å›¾"]:
                        full_key = look_around_for_context(table, r, c)
                    
                    target_coords = None
                    
                    # ç­–ç•¥ 1: å‘å³çœ‹
                    if c + 1 < cols:
                        right_cell = table.cell(r, c + 1)
                        if not right_cell.text.strip() and (t_idx, r, c+1) not in processed_targets:
                            target_coords = (t_idx, r, c + 1)
                    
                    # ç­–ç•¥ 2: å‘ä¸‹çœ‹ (å¦‚æœå‘å³æ²¡æ‰¾åˆ°)
                    if target_coords is None and r + 1 < rows:
                         down_cell = table.cell(r + 1, c)
                         if not down_cell.text.strip() and (t_idx, r+1, c) not in processed_targets:
                             target_coords = (t_idx, r + 1, c)

                    if target_coords:
                        structure.append({
                            'key_text': full_key, # ä½¿ç”¨ä¸Šä¸‹æ–‡å¢å¼ºçš„ Key
                            'original_text': text,
                            'key_coords': (t_idx, r, c),
                            'target_coords': target_coords
                        })
                        processed_targets.add(target_coords)
                        
                except IndexError:
                    continue
    
    if logger: logger.log(f"æ–‡æ¡£æ‰«æå®Œæˆï¼Œå…±è¯†åˆ«åˆ° {len(structure)} ä¸ªå¡«ç©ºç‚¹ã€‚", "âœ…")
    return structure

# --- Logic: Agentic Generation ---
def generate_deep_content(user_inputs, doc_keys, api_key, logger):
    """
    ä½¿ç”¨â€œæ€ç»´é“¾â€æ–¹æ³•ç”Ÿæˆå†…å®¹ã€‚
    1. ç ”ç©¶/Keyåˆ†æï¼šæœç´¢æ•™å­¦é‡ç‚¹å’Œè§£å†³æªæ–½ã€‚
    2. ç”Ÿæˆï¼šåˆ›å»ºå…·ä½“å†…å®¹ (è¯¾å‰/è¯¾ä¸­/è¯¾å)ã€‚
    3. æ˜ å°„ï¼šè¿”å› JSON æ ¼å¼ç»“æœã€‚
    """
    llm = ChatOpenAI(
        model="deepseek-chat", 
        temperature=0.7,
        base_url="https://api.deepseek.com",
        openai_api_key=api_key
    )
    
    # 1. ç ”ç©¶é˜¶æ®µ
    logger.log(f"æ­£åœ¨åˆ†æè¯¾ç¨‹ä¸»é¢˜: {user_inputs['è¯¾ç¨‹å¤§çº²']}...", "ğŸ§ ")
    logger.log("æ­£åœ¨è”ç½‘æ£€ç´¢(æ¨¡æ‹Ÿ) æ•™å­¦é‡ç‚¹ã€éš¾ç‚¹åŠè§£å†³æªæ–½...", "ğŸ”")
    
    # 2. ç”Ÿæˆ Prompt
    keys_list = [item['key_text'] for item in doc_keys]
    
    system_prompt = """
    ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é‡‘ç‰Œè®²å¸ˆåŠæ•™æ¡ˆç¼–å†™ä¸“å®¶ã€‚
    è¯·æ ¹æ®ã€ç”¨æˆ·è¾“å…¥ã€‘çš„ä¿¡æ¯ï¼Œä¸ºä¸€ä»½æ•™æ¡ˆå¡«å……å†…å®¹ã€‚
    
    å…³é”®è¦æ±‚ï¼š
    1. **æ•™å­¦é‡ç‚¹ä¸è§£å†³æªæ–½**ï¼šå¿…é¡»ç”Ÿæˆå…·ä½“ã€ä¸“ä¸šçš„çŸ¥è¯†ç‚¹å’Œæ•™å­¦ç­–ç•¥ï¼Œç»ä¸èƒ½ç•™ç©ºã€‚
    2. **æ•™å­¦è¿‡ç¨‹ï¼ˆè¯¾å‰/è¯¾ä¸­/è¯¾åï¼‰**ï¼š
       - è¯·æ ¹æ®è¯¾ç¨‹ä¸»é¢˜ï¼Œè‡ªåŠ¨è®¾è®¡ "è¯¾å‰é¢„ä¹ ä»»åŠ¡"ã€"è¯¾ä¸­å¯¼å…¥/è®²æˆ/ç»ƒä¹ "ã€"è¯¾åæ‹“å±•" çš„å…·ä½“ç¯èŠ‚ã€‚
       - è¯†åˆ«æ–‡æ¡£Keyä¸­çš„ä¸Šä¸‹æ–‡ï¼ˆå¦‚ "è¯¾å‰ > å†…å®¹"ï¼‰ï¼Œå¡«å…¥å¯¹åº”çš„è®¾è®¡å†…å®¹ã€‚
    3. **æ•™æ¡ˆåºå·**ï¼šå¦‚æœç”¨æˆ·æœªå¡«ï¼Œè¯·è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªåˆç†çš„åºå·ï¼ˆå¦‚ "No. 2024-01"ï¼‰ã€‚
    4. **è¯¾ç¨‹æ€§è´¨**ï¼šå¦‚æœæ–‡æ¡£æœ‰æ­¤å­—æ®µï¼Œæ ¹æ®è¯¾ç¨‹å†…å®¹è‡ªåŠ¨åˆ¤æ–­ï¼ˆå¦‚ "ç†è®ºè¯¾" æˆ– "ç†å®ä¸€ä½“"ï¼‰ã€‚
    
    è¯·è¾“å‡ºä¸€ä¸ªçº¯ JSON å¯¹è±¡ï¼Œæ ¼å¼ä¸º {{ "æ–‡æ¡£é‡Œçš„Key": "ä½ çš„å»ºè®®å†…å®¹" }}ã€‚
    """
    
    human_template = """
    ã€ç”¨æˆ·è¾“å…¥ã€‘: {user_inputs}
    
    ã€æ–‡æ¡£æ‰€æœ‰å¾…å¡«å­—æ®µ (Keys)ã€‘: {keys_list}
    
    è¯·å¼€å§‹ç¼–å†™ï¼Œç¡®ä¿æ‰€æœ‰å­—æ®µï¼ˆå°¤å…¶æ˜¯æ•™å­¦è¿‡ç¨‹å’Œé‡ç‚¹ï¼‰éƒ½æœ‰ä¸°å¯Œçš„å†…å®¹ã€‚
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", human_template)
    ])
    
    chain = prompt | llm
    
    logger.log("æ­£åœ¨æ’°å†™æ•™æ¡ˆè¯¦ç»†å†…å®¹ (è¿™å¯èƒ½éœ€è¦ 30-60 ç§’)...", "âœï¸")
    
    try:
        response = chain.invoke({
            "user_inputs": json.dumps(user_inputs, ensure_ascii=False),
            "keys_list": json.dumps(keys_list, ensure_ascii=False)
        })
        
        content = response.content
        # ç¨³å¥çš„ JSON æå–
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        logger.log("AI æ’°å†™å®Œæˆï¼æ­£åœ¨å‡†å¤‡å†™å…¥...", "âœ¨")
        return json.loads(content)
        
    except Exception as e:
        logger.log(f"ç”Ÿæˆå‡ºé”™: {e}", "âŒ")
        st.error(f"Generate Error: {e}")
        return {}

def set_cell_text_preserving_style(cell, text):
    if not cell.paragraphs:
        cell.add_paragraph(text)
        return

    paragraph = cell.paragraphs[0]
    style_run = paragraph.runs[0] if paragraph.runs else None
    
    paragraph.clear()
    run = paragraph.add_run(text)
    
    if style_run:
        run.bold = style_run.bold
        run.italic = style_run.italic
        run.font.name = style_run.font.name
        if style_run.font.size:
            run.font.size = style_run.font.size

# --- Main App ---

def main():
    st.markdown("## ğŸ¤– AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (Pro)")
    
    # 0. Global Logger
    logger = ConsoleLogger()

    # 1. Sidebar Config
    with st.sidebar:
        st.header("âš™ï¸ 1. åŸºç¡€é…ç½®")
        api_key = st.text_input("DeepSeek API Key", type="password")
        
        st.header("ğŸ“ 2. è¯¾ç¨‹åŸºç¡€ä¿¡æ¯")
        
        # New: Serial Number
        col1, col2 = st.columns(2)
        serial_no = col1.text_input("æ•™æ¡ˆåºå·", "No. 01")
        time_val = col2.text_input("æˆè¯¾æ—¶é—´", "2024-03-20")

        dept = st.text_input("éƒ¨é—¨/é™¢ç³»", "ä¿¡æ¯å·¥ç¨‹å­¦é™¢")
        teacher = st.text_input("æ•™å¸ˆå§“å", "å¼ ä¸‰")
        
        # New: Selectors for common fields
        course_type = st.selectbox("è¯¾ç¨‹æ€§è´¨ (AIå¯è¦†ç›–)", ["ç†è®ºè¯¾", "å®è·µè¯¾", "ç†å®ä¸€ä½“åŒ–", "ç ”è®¨è¯¾"])
        
        user_inputs = {
            "æ•™æ¡ˆåºå·": serial_no,
            "æ—¶é—´": time_val,
            "éƒ¨é—¨": dept,
            "æ•™å¸ˆå§“å": teacher,
            "è¯¾ç¨‹æ€§è´¨": course_type
        }

        with st.expander("ğŸ“š æ›´å¤šè¯¾ç¨‹ç»†èŠ‚ (é€‰å¡«)", expanded=False):
            user_inputs["è¯¾ç¨‹åç§°"] = st.text_input("è¯¾ç¨‹åç§°", "Python ç¨‹åºè®¾è®¡")
            user_inputs["ç­çº§"] = st.text_input("ç­çº§", "23çº§è®¡ç®—æœº1ç­")
            user_inputs["åœ°ç‚¹"] = st.text_input("æˆè¯¾åœ°ç‚¹", "A305")
            user_inputs["æˆè¯¾å­¦æ—¶"] = st.number_input("å­¦æ—¶", 1, 4, 2)
            user_inputs["æˆè¯¾å½¢å¼"] = st.selectbox("æˆè¯¾å½¢å¼", ["çº¿ä¸‹é¢æˆ", "çº¿ä¸Šç›´æ’­", "æ··åˆå¼æ•™å­¦"])
            user_inputs["ä½¿ç”¨æ•™æ"] = st.text_input("ä½¿ç”¨æ•™æ", "ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹")
            user_inputs["è€ƒæ ¸æ–¹å¼"] = st.selectbox("è€ƒæ ¸æ–¹å¼", ["è€ƒæŸ¥", "è€ƒè¯•", "è¿‡ç¨‹åŒ–è€ƒæ ¸"])

        st.header("ğŸ§  3. æ ¸å¿ƒå†…å®¹è¾“å…¥")
        topic_outline = st.text_area("æœ¬èŠ‚è¯¾ä¸»é¢˜ & å¤§çº²", height=250, 
                                     placeholder="è¾“å…¥æœ¬èŠ‚è¯¾çš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼š\nä¸»é¢˜ï¼šPython å¾ªç¯ç»“æ„\n1. while å¾ªç¯\n2. fo å¾ªç¯\n3. æ¡ˆä¾‹å®æˆ˜")
        user_inputs["è¯¾ç¨‹å¤§çº²"] = topic_outline

    # 2. Main Area
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  Word æ•™æ¡ˆæ¨¡æ¿ (.docx)", type=["docx"])

    if uploaded_file and st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ DeepSeek API Key")
            return
        
        if not topic_outline:
            st.warning("è¯·å¡«å†™ã€è¯¾ç¨‹ä¸»é¢˜ & å¤§çº²ã€‘ï¼Œå¦åˆ™ AI æ— æ³•ç”Ÿæˆå†…å®¹ã€‚")
            return

        # Step 1: Parse
        doc = Document(uploaded_file)
        structure = get_table_structure_v2(doc, logger)
        
        if not structure:
            st.warning("æœªèƒ½è¯†åˆ«åˆ°è¡¨æ ¼ç»“æ„ã€‚è¯·ç¡®ä¿æ–‡æ¡£åŒ…å«æ ‡å‡†è¡¨æ ¼ã€‚")
            return

        # Step 2: Generate
        mapping = generate_deep_content(user_inputs, structure, api_key, logger)
        
        # Step 3: Fill
        logger.log("æ­£åœ¨å°†å†…å®¹å†™å…¥æ–‡æ¡£...", "ğŸ’¾")
        fill_count = 0
        
        # Progress bar
        my_bar = st.progress(0)
        total_items = len(structure)
        
        for i, item in enumerate(structure):
            key = item['key_text']
            target_coords = item['target_coords']
            original_text = item['original_text']
            
            # Try to find match in generated mapping
            # Priority: Full Contextual Key -> Original Text -> Partial Match
            content = mapping.get(key) or mapping.get(original_text)
            
            if content:
                t_idx, r, c = target_coords
                target_cell = doc.tables[t_idx].cell(r, c)
                set_cell_text_preserving_style(target_cell, str(content))
                fill_count += 1
                if i % 5 == 0: # Log partially
                     logger.log(f"å·²å¡«å…¥: {key} -> {str(content)[:10]}...", "ğŸ“")
            
            my_bar.progress(min((i + 1) / total_items, 1.0))

        logger.log(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±å¡«å…… {fill_count} ä¸ªå­—æ®µã€‚", "âœ…")
        st.success(f"ç”ŸæˆæˆåŠŸï¼")

        buffer = BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„æ•™æ¡ˆ",
            data=buffer,
            file_name="generated_lesson_plan_v2.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    
if __name__ == "__main__":
    main()
