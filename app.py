import streamlit as st
import os
from docx import Document
from docx.shared import Pt
import json
import time
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from io import BytesIO

# --- Configuration ---
st.set_page_config(page_title="AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (V11 Fixed)", layout="wide", initial_sidebar_state="expanded")

# --- UI Components: Console Logger ---
class ConsoleLogger:
    def __init__(self):
        self.container = st.empty()
        self.logs = []

    def log(self, message, icon="ğŸ¤–"):
        timestamp = time.strftime("%H:%M:%S")
        self.logs.append(f"`{timestamp}` {icon} {message}")
        with self.container.container():
            with st.expander("ğŸ–¥ï¸ AI è¿è¡Œç»ˆç«¯ (å®æ—¶æ—¥å¿—)", expanded=True):
                for log in self.logs[-5:]: # Show last 5 logs
                    st.markdown(log)
    
    def clear(self):
        self.container.empty()
        self.logs = []

# --- Logic: Smart Parsing V10 ---
def get_cell_text(cell):
    return cell.text.strip()

def set_cell_text_preserving_style(cell, text):
    """ä¿ç•™åŸæœ‰æ ¼å¼å†™å…¥æ–‡æœ¬"""
    if not cell.paragraphs:
        cell.add_paragraph(text)
        return

    paragraph = cell.paragraphs[0]
    style_run = paragraph.runs[0] if paragraph.runs else None
    
    paragraph.clear()
    run = paragraph.add_run(text)
    
    if style_run:
        run.bold = style_run.bold
        run.italic = style_run.italic
        run.font.name = style_run.font.name
        if style_run.font.size:
            run.font.size = style_run.font.size

def get_table_structure_v10(doc, logger=None):
    """
    ã€V10 ç»ˆæä¿®è¡¥ç‰ˆã€‘
    1. å¢åŠ æŠ“å– "æ•™å­¦ç¯èŠ‚" åˆ—ã€‚
    2. è§£é”è¡Œæ•°é™åˆ¶ (MAX_ROWS = 50)ã€‚
    3. ä¼˜åŒ– Key ç”Ÿæˆé€»è¾‘ã€‚
    """
    if logger: logger.log("æ­£åœ¨æ‰§è¡Œå…¨é‡æ·±åº¦æ‰«æ (V10 åŒ…å«è¯¾åä¿®å¤)...", "ğŸ”")
    
    structure = []
    processed_cell_ids = set() 
    processed_keys = set()     

    MAX_ROWS_PER_PHASE = 50 

    def is_instructional(text):
        return len(text) > 30 or any(k in text for k in ["æ€æ”¿æ¡ˆä¾‹", "ç¡®ä¿æ€æ”¿", "æ¯”ä¾‹å¯æ ¹æ®"])

    for t_idx, table in enumerate(doc.tables):
        rows = table.rows
        all_text = "".join([c.text for r in rows for c in r.cells])
        
        # --- ç­–ç•¥ Aï¼šæ•™å­¦è¿‡ç¨‹çŸ©é˜µè¡¨ (Index 1) ---
        if any(k in all_text for k in ["æ•™å¸ˆæ´»åŠ¨", "å­¦ç”Ÿæ´»åŠ¨", "è®¾è®¡æ„å›¾"]):
            if logger: logger.log(f"æ­£åœ¨è§£ææ•™å­¦è¿‡ç¨‹è¡¨ï¼Œå‡†å¤‡æå–å…¨éƒ¨è¡Œ...", "ğŸ¯")
            
            col_map = {}
            for r_idx in range(min(3, len(rows))):
                for c_idx in range(len(table.columns)):
                    txt = table.cell(r_idx, c_idx).text.strip()
                    if txt in ["æ•™å­¦ç¯èŠ‚", "æ•™å­¦å†…å®¹", "æ•™å¸ˆæ´»åŠ¨", "å­¦ç”Ÿæ´»åŠ¨", "è®¾è®¡æ„å›¾"]:
                        col_map[c_idx] = txt

            current_phase = "æ•™å­¦è¿‡ç¨‹"
            phase_counter = {} 

            for r in range(len(rows)):
                row_raw_text = "".join(list(dict.fromkeys([c.text.strip() for c in rows[r].cells])))
                
                if row_raw_text in ["è¯¾å‰", "è¯¾ä¸­", "è¯¾å", "å·©å›ºæ‹“å±•"]:
                    current_phase = row_raw_text
                    phase_counter[current_phase] = 0
                    continue
                
                if phase_counter.get(current_phase, 0) >= MAX_ROWS_PER_PHASE:
                    continue

                row_has_vacancy = False
                for c_idx, col_name in col_map.items():
                    target_cell = table.cell(r, c_idx)
                    if not target_cell.text.strip() and target_cell.text.strip() != col_name:
                        if target_cell._tc not in processed_cell_ids:
                            row_has_vacancy = True
                            full_key = f"{current_phase} > {col_name}_è¡Œ{r}"
                            
                            structure.append({
                                'key_text': full_key,
                                'original_text': col_name,
                                'target_coords': (t_idx, r, c_idx),
                                'is_teaching_process': True
                            })
                            processed_cell_ids.add(target_cell._tc)
                
                if row_has_vacancy:
                    phase_counter[current_phase] = phase_counter.get(current_phase, 0) + 1
            continue

        # --- ç­–ç•¥ Bï¼šé€šç”¨ä¿¡æ¯è¡¨ ---
        for r in range(len(rows)):
            for c in range(len(table.columns)):
                cell = table.cell(r, c)
                text = cell.text.strip().replace("\n", "").replace(" ", "")
                
                if not text or is_instructional(text): continue
                if text in processed_keys and len(text) < 10: continue

                target = None
                if c + 1 < len(table.columns):
                    r_c = table.cell(r, c + 1)
                    if not r_c.text.strip(): target = (r, c + 1, r_c._tc)
                if not target and r + 1 < len(rows):
                    d_c = table.cell(r + 1, c)
                    if not d_c.text.strip(): target = (r + 1, c, d_c._tc)
                
                if target:
                    tr, tc, t_id = target
                    if t_id not in processed_cell_ids:
                        full_key = text
                        p_header = table.cell(r, 0).text.strip()
                        if p_header in ["å­¦æƒ…åˆ†æ", "æ•™å­¦ç›®æ ‡", "æ•™å­¦èµ„æº", "æ•™å­¦åæ€"]:
                            if p_header != text: full_key = f"{p_header} > {text}"

                        structure.append({
                            'key_text': full_key,
                            'original_text': text,
                            'target_coords': (t_idx, tr, tc),
                            'is_teaching_process': False
                        })
                        processed_cell_ids.add(t_id)
                        processed_keys.add(text)

    return structure

# --- Logic: Agentic Generation ---
def generate_deep_content(user_inputs, doc_keys, api_key, logger):
    """
    Prompt å‡çº§ç‰ˆï¼š
    ä¿®å¤äº† JSON ç¤ºä¾‹èŠ±æ‹¬å·æœªè½¬ä¹‰å¯¼è‡´çš„ LangChain æŠ¥é”™ã€‚
    """
    llm = ChatOpenAI(
        model="deepseek-chat", 
        temperature=0.7,
        base_url="https://api.deepseek.com",
        openai_api_key=api_key
    )
    
    # 1. ç ”ç©¶é˜¶æ®µ
    logger.log(f"æ­£åœ¨æ·±åº¦åˆ†æ: {user_inputs['è¯¾ç¨‹å¤§çº²']}", "ğŸ§ ")
    logger.log("æ­£åœ¨æŒ–æ˜æ€æ”¿èåˆç‚¹ & æ•™å­¦è§£å†³æªæ–½...", "ğŸ”")
    
    keys_list = [item['key_text'] for item in doc_keys]
    
    # æ³¨æ„ï¼šè¿™é‡Œçš„ JSON ç¤ºä¾‹å·²ç»æ”¹æˆäº† {{ ... }}ï¼Œè¿™å°±æ˜¯ä¿®å¤ç‚¹ï¼
    system_prompt = """
ä½ æ˜¯ä¸€ä½é¡¶å°–çš„èŒä¸šæ•™è‚²/é«˜ç­‰æ•™è‚²æ•™æ¡ˆç¼–å†™ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„åŸºç¡€ä¿¡æ¯ï¼Œå¡«æ»¡æ–‡æ¡£ä¸­æ‰€æœ‰çš„ç©ºç¼ºå­—æ®µã€‚

## âš ï¸ æœ€é«˜ä¼˜å…ˆçº§æŒ‡ä»¤ï¼ˆå¿…é¡»ä¸¥æ ¼æ‰§è¡Œï¼‰

1.  **ç”¨æˆ·è¾“å…¥ä¼˜å…ˆ**ï¼š
    -   å¦‚æœ Key æ˜¯ "æˆè¯¾æ—¶é—´"ã€"æˆè¯¾åœ°ç‚¹"ã€"ç­çº§"ã€"æ•™å¸ˆå§“å"ï¼Œ**å¿…é¡»ç›´æ¥ä½¿ç”¨ã€ç”¨æˆ·è¾“å…¥ã€‘ä¸­çš„å¯¹åº”å€¼**ï¼Œä¸¥ç¦è‡ªå·±ç¼–é€ æˆ–ç•™ç©ºã€‚

2.  **å¿…é¡»å¡«æ»¡æ‰€æœ‰æ•™å­¦è¿‡ç¨‹çš„æ ¼å­**ï¼š
    -   ä½ ä¼šæ”¶åˆ°åƒ "è¯¾ä¸­ > æ•™å¸ˆæ´»åŠ¨_è¡Œ10", "è¯¾ä¸­ > æ•™å¸ˆæ´»åŠ¨_è¡Œ11" è¿™æ ·çš„å¤§é‡ Keyã€‚
    -   **æœ‰å¤šå°‘ä¸ª Keyï¼Œå°±å¿…é¡»è¾“å‡ºå¤šå°‘æ¡å†…å®¹ï¼** ä¸¥ç¦åˆå¹¶ï¼Œä¸¥ç¦å·æ‡’ï¼Œä¸¥ç¦åªå†™å‰å‡ è¡Œã€‚
    -   å¦‚æœæ˜¯ "è¯¾å" ç¯èŠ‚ï¼Œå³ä½¿æœ‰å¾ˆå¤šè¡Œï¼Œä¹Ÿè¦åˆ†åˆ«å¡«å†™ï¼ˆå¦‚ï¼šå¸ƒç½®ä½œä¸šã€é¢„ä¹ ä¸‹èŠ‚ã€æ•´ç†ç¬”è®°ç­‰ï¼‰ã€‚
    -   **"æ•™å­¦ç¯èŠ‚" åˆ—**ï¼šè¯·å¡«å…¥ç®€çŸ­çš„æ­¥éª¤åç§°ï¼Œå¦‚ "å¯¼å…¥æ–°è¯¾"ã€"æ¡ˆä¾‹åˆ†æ"ã€"å°ç»„è®¨è®º"ã€"è¯¾å ‚æ€»ç»“"ã€‚

3.  **ç‰¹æ®Šå­—æ®µå†…å®¹è¦æ±‚**ï¼š
    -   **"è¯¾ç¨‹æ€æ”¿èåˆç‚¹" / "ç´ è´¨ç›®æ ‡"**ï¼šè¯·åŠ¡å¿…è¿›è¡Œâ€œè”ç½‘æœç´¢å¼â€åˆ›ä½œï¼Œç»“åˆè¯¾ç¨‹å†…å®¹ï¼Œå¡«å…¥å…·ä½“çš„å®¶å›½æƒ…æ€€ã€èŒä¸šé“å¾·ã€å·¥åŒ ç²¾ç¥ã€ç§‘å­¦æ€ç»´ç­‰èåˆç‚¹ã€‚**ç»å¯¹ä¸èƒ½ç•™ç©ºï¼**
    -   **"è§£å†³æªæ–½"**ï¼šæ¯ä¸€ä¸ª "æ•™å­¦éš¾ç‚¹" å¯¹åº”çš„åœ°æ–¹ï¼Œå¿…é¡»å¡«å…¥å…·ä½“çš„ "è§£å†³æªæ–½"ã€‚

4.  **å†…å®¹è¿è´¯æ€§**ï¼š
    -   "è¯¾ä¸­" çš„å¤šè¡Œå†…å®¹åº”æ„æˆä¸€ä¸ªå®Œæ•´çš„æ•™å­¦æµã€‚ä¾‹å¦‚ï¼š_è¡Œ8 æ˜¯å¯¼å…¥ï¼Œ_è¡Œ9-15 æ˜¯è®²è§£ï¼Œ_è¡Œ16-20 æ˜¯ç»ƒä¹ ã€‚

## è¾“å‡ºæ ¼å¼
-   è¾“å‡ºçº¯ JSON å¯¹è±¡ï¼š`{{ "Keyçš„åå­—": "å¡«å……å†…å®¹" }}`
-   ä¸è¦è¾“å‡º Markdown ä»£ç å—æ ‡è®°ã€‚
"""
    
    human_template = """
    ã€ç”¨æˆ·è¾“å…¥æ•°æ®ã€‘: {user_inputs}
    
    ã€éœ€è¦å¡«å……çš„æ‰€æœ‰ Keyã€‘: {keys_list}
    
    è¯·å¼€å§‹ç”Ÿæˆã€‚è¯·è®°ä½ï¼šæˆè¯¾æ—¶é—´ç”¨ç”¨æˆ·è¾“å…¥çš„ï¼›æ€æ”¿ç‚¹è¦å…·ä½“ï¼›æ•™å­¦è¿‡ç¨‹çš„æ¯ä¸€è¡Œéƒ½è¦å¡«æ»¡ï¼Œä¸è¦é—æ¼è¯¾åç¯èŠ‚ã€‚
    """
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", human_template)
    ])
    
    chain = prompt | llm
    
    logger.log("AI æ­£åœ¨æ ¹æ®æ ¼å­æ•°é‡æ’°å†™å…¨é‡æ•™æ¡ˆ (å†…å®¹è¾ƒå¤šï¼Œè¯·è€å¿ƒç­‰å¾…)...", "âœï¸")
    
    try:
        response = chain.invoke({
            "user_inputs": json.dumps(user_inputs, ensure_ascii=False),
            "keys_list": json.dumps(keys_list, ensure_ascii=False)
        })
        
        content = response.content
        if "```json" in content:
            content = content.split("```json")[1].split("```")[0]
        elif "```" in content:
            content = content.split("```")[1].split("```")[0]
            
        result = json.loads(content)
        
        # --- ç¡¬é€»è¾‘è¡¥ä¸ ---
        user_mapping = {
            "æˆè¯¾æ—¶é—´": user_inputs.get("æ—¶é—´"),
            "æ•™æ¡ˆåºå· > æˆè¯¾æ—¶é—´": user_inputs.get("æ—¶é—´"),
            "æˆè¯¾åœ°ç‚¹": user_inputs.get("åœ°ç‚¹"),
            "æ•™æ¡ˆåºå· > æˆè¯¾åœ°ç‚¹": user_inputs.get("åœ°ç‚¹"),
            "æˆè¯¾ç­çº§": user_inputs.get("ç­çº§"),
            "æˆè¯¾å†…å®¹ > æˆè¯¾ç­çº§": user_inputs.get("ç­çº§"),
            "æ•™å¸ˆå§“å": user_inputs.get("æ•™å¸ˆå§“å")
        }
        
        for k, v in user_mapping.items():
            if v:
                result[k] = v
                
        logger.log("AI æ’°å†™å®Œæˆï¼æ­£åœ¨å†™å…¥æ–‡æ¡£...", "âœ¨")
        return result
        
    except Exception as e:
        logger.log(f"ç”Ÿæˆå‡ºé”™: {e}", "âŒ")
        st.error(f"Generate Error: {e}")
        return {}

# --- Main App ---

def main():
    st.markdown("## ğŸ¤– AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (V11 Pro)")
    
    # 0. Global Logger
    logger = ConsoleLogger()

    # 1. Sidebar Config
    with st.sidebar:
        st.header("âš™ï¸ 1. åŸºç¡€é…ç½®")
        api_key = st.text_input("DeepSeek API Key", type="password")
        
        st.header("ğŸ“ 2. è¯¾ç¨‹åŸºç¡€ä¿¡æ¯")
        
        # New: Serial Number
        col1, col2 = st.columns(2)
        serial_no = col1.text_input("æ•™æ¡ˆåºå·", "No. 01")
        time_val = col2.text_input("æˆè¯¾æ—¶é—´", "2024-03-20")

        dept = st.text_input("éƒ¨é—¨/é™¢ç³»", "ä¿¡æ¯å·¥ç¨‹å­¦é™¢")
        teacher = st.text_input("æ•™å¸ˆå§“å", "å¼ ä¸‰")
        
        # New: Selectors for common fields
        course_type = st.selectbox("è¯¾ç¨‹æ€§è´¨ (AIå¯è¦†ç›–)", ["ç†è®ºè¯¾", "å®è·µè¯¾", "ç†å®ä¸€ä½“åŒ–", "ç ”è®¨è¯¾"])
        
        user_inputs = {
            "æ•™æ¡ˆåºå·": serial_no,
            "æ—¶é—´": time_val,
            "éƒ¨é—¨": dept,
            "æ•™å¸ˆå§“å": teacher,
            "è¯¾ç¨‹æ€§è´¨": course_type
        }

        with st.expander("ğŸ“š æ›´å¤šè¯¾ç¨‹ç»†èŠ‚ (é€‰å¡«)", expanded=False):
            user_inputs["è¯¾ç¨‹åç§°"] = st.text_input("è¯¾ç¨‹åç§°", "Python ç¨‹åºè®¾è®¡")
            user_inputs["ç­çº§"] = st.text_input("ç­çº§", "23çº§è®¡ç®—æœº1ç­")
            user_inputs["åœ°ç‚¹"] = st.text_input("æˆè¯¾åœ°ç‚¹", "A305")
            user_inputs["æˆè¯¾å­¦æ—¶"] = st.number_input("å­¦æ—¶", 1, 4, 2)
            user_inputs["æˆè¯¾å½¢å¼"] = st.selectbox("æˆè¯¾å½¢å¼", ["çº¿ä¸‹é¢æˆ", "çº¿ä¸Šç›´æ’­", "æ··åˆå¼æ•™å­¦"])
            user_inputs["ä½¿ç”¨æ•™æ"] = st.text_input("ä½¿ç”¨æ•™æ", "ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹")
            user_inputs["è€ƒæ ¸æ–¹å¼"] = st.selectbox("è€ƒæ ¸æ–¹å¼", ["è€ƒæŸ¥", "è€ƒè¯•", "è¿‡ç¨‹åŒ–è€ƒæ ¸"])

        st.header("ğŸ§  3. æ ¸å¿ƒå†…å®¹è¾“å…¥")
        topic_outline = st.text_area("æœ¬èŠ‚è¯¾ä¸»é¢˜ & å¤§çº²", height=250, 
                                     placeholder="è¾“å…¥æœ¬èŠ‚è¯¾çš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼š\nä¸»é¢˜ï¼šPython å¾ªç¯ç»“æ„\n1. while å¾ªç¯\n2. fo å¾ªç¯\n3. æ¡ˆä¾‹å®æˆ˜")
        user_inputs["è¯¾ç¨‹å¤§çº²"] = topic_outline

    # 2. Main Area
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  Word æ•™æ¡ˆæ¨¡æ¿ (.docx)", type=["docx"])

    if uploaded_file and st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ DeepSeek API Key")
            return
        
        if not topic_outline:
            st.warning("è¯·å¡«å†™ã€è¯¾ç¨‹ä¸»é¢˜ & å¤§çº²ã€‘ï¼Œå¦åˆ™ AI æ— æ³•ç”Ÿæˆå†…å®¹ã€‚")
            return

        # Step 1: Parse
        doc = Document(uploaded_file)
        structure = get_table_structure_v10(doc, logger)
        
        if not structure:
            st.warning("æœªèƒ½è¯†åˆ«åˆ°è¡¨æ ¼ç»“æ„ã€‚è¯·ç¡®ä¿æ–‡æ¡£åŒ…å«æ ‡å‡†è¡¨æ ¼ã€‚")
            return

        # Step 2: Generate
        mapping = generate_deep_content(user_inputs, structure, api_key, logger)
        
        # Step 3: Fill
        logger.log("æ­£åœ¨å°†å†…å®¹å†™å…¥æ–‡æ¡£...", "ğŸ’¾")
        fill_count = 0
        
        # Progress bar
        my_bar = st.progress(0)
        total_items = len(structure)
        
        for i, item in enumerate(structure):
            key = item['key_text']
            target_coords = item['target_coords']
            original_text = item['original_text']
            
            # Try to find match in generated mapping
            content = mapping.get(key) or mapping.get(original_text)
            
            if content:
                t_idx, r, c = target_coords
                target_cell = doc.tables[t_idx].cell(r, c)
                set_cell_text_preserving_style(target_cell, str(content))
                fill_count += 1
                if i % 10 == 0: 
                     logger.log(f"å·²å¡«å…¥: {key} -> {str(content)[:10]}...", "ğŸ“")
            
            my_bar.progress(min((i + 1) / total_items, 1.0))

        logger.log(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±å¡«å…… {fill_count} ä¸ªå­—æ®µã€‚", "âœ…")
        st.success(f"ç”ŸæˆæˆåŠŸï¼")

        buffer = BytesIO()
        doc.save(buffer)
        buffer.seek(0)
        
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„æ•™æ¡ˆ",
            data=buffer,
            file_name="generated_lesson_plan_v11.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
    
if __name__ == "__main__":
    main()