import streamlit as st
import os
from docx import Document
from docx.shared import Pt
import json
import time
import re
import math
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from io import BytesIO

# --- Configuration ---
st.set_page_config(page_title="AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (V16 Flagship)", layout="wide", initial_sidebar_state="expanded")

# --- UI Components: Console Logger ---
class ConsoleLogger:
    def __init__(self):
        self.container = st.empty()
        self.logs = []

    def log(self, message, icon="ğŸ¤–"):
        timestamp = time.strftime("%H:%M:%S")
        self.logs.append(f"`{timestamp}` {icon} {message}")
        with self.container.container():
            with st.expander("ğŸ–¥ï¸ AI è¿è¡Œç»ˆç«¯ (å®æ—¶æ—¥å¿—)", expanded=True):
                for log in self.logs[-5:]: # Show last 5 logs
                    st.markdown(log)
    
    def clear(self):
        self.container.empty()
        self.logs = []

# --- Logic: Helper Functions ---
def set_cell_text_preserving_style(cell, text):
    """ä¿ç•™åŸæœ‰æ ¼å¼å†™å…¥æ–‡æœ¬"""
    if not cell.paragraphs:
        cell.add_paragraph(text)
        return

    paragraph = cell.paragraphs[0]
    style_run = paragraph.runs[0] if paragraph.runs else None
    
    paragraph.clear()
    run = paragraph.add_run(text)
    
    if style_run:
        run.bold = style_run.bold
        run.italic = style_run.italic
        run.font.name = style_run.font.name
        if style_run.font.size:
            run.font.size = style_run.font.size

def extract_json_safe(content):
    """
    JSON æå–ä¸ä¿®å¤ (V14+)
    """
    if "```json" in content:
        content = content.split("```json")[1].split("```")[0]
    elif "```" in content:
        content = content.split("```")[1].split("```")[0]
    
    content = content.strip()
    # ä¿®å¤å°¾éƒ¨é€—å·
    content = re.sub(r',(\s*})', r'\1', content)
    content = re.sub(r',(\s*])', r'\1', content)
    
    try:
        return json.loads(content)
    except Exception:
        return None

# --- Logic: Structure Parsing (V16 Optimized) ---
def get_table_structure(doc, logger=None):
    """
    ã€V16 ç»“æ„è§£æå¼•æ“ã€‘
    1. æ™ºèƒ½å¤„ç†è·¨é¡µé‡å¤è¡¨å¤´ï¼ˆå¿½ç•¥é‡å¤çš„çº¢è‰²â€œè¯¾ä¸­â€ï¼‰ã€‚
    2. ç¡®ä¿æŠ“å–åˆ°â€œè¯¾åâ€å’Œâ€œå·©å›ºæ‹“å±•â€ã€‚
    3. å…¨å±€å”¯ä¸€è¡Œå· Keyã€‚
    """
    if logger: logger.log("æ­£åœ¨æ‰«ææ–‡æ¡£ç»“æ„ (V16 æ™ºèƒ½ç‰ˆ)...", "ğŸ”")
    
    structure = []
    processed_cell_ids = set() 
    processed_keys = set()     

    # åªè¦ä¸æ˜¯æ­»å¾ªç¯ï¼Œå°½å¯èƒ½å¤šæŠ“ï¼Œç”± Prompt æ§åˆ¶å†…å®¹
    MAX_ROWS_PER_PHASE = 100 

    def is_instructional(text):
        return len(text) > 30 or any(k in text for k in ["æ€æ”¿æ¡ˆä¾‹", "ç¡®ä¿æ€æ”¿", "æ¯”ä¾‹å¯æ ¹æ®"])

    for t_idx, table in enumerate(doc.tables):
        rows = table.rows
        all_text = "".join([c.text for r in rows for c in r.cells])
        
        # --- ç­–ç•¥ Aï¼šæ•™å­¦è¿‡ç¨‹çŸ©é˜µè¡¨ ---
        if any(k in all_text for k in ["æ•™å¸ˆæ´»åŠ¨", "å­¦ç”Ÿæ´»åŠ¨", "è®¾è®¡æ„å›¾"]):
            if logger: logger.log(f"æ­£åœ¨è§£ææ•™å­¦è¿‡ç¨‹è¡¨...", "ğŸ¯")
            
            col_map = {}
            # æ‰«æå‰å‡ è¡Œæ‰¾åˆ—å
            for r_idx in range(min(5, len(rows))):
                for c_idx in range(len(table.columns)):
                    txt = table.cell(r_idx, c_idx).text.strip()
                    if txt in ["æ•™å­¦ç¯èŠ‚", "æ•™å­¦å†…å®¹", "æ•™å¸ˆæ´»åŠ¨", "å­¦ç”Ÿæ´»åŠ¨", "è®¾è®¡æ„å›¾"]:
                        col_map[c_idx] = txt

            current_phase = "æ•™å­¦è¿‡ç¨‹"
            # ä½¿ç”¨åˆ—è¡¨æ¥è®°å½•å·²å¤„ç†çš„é˜¶æ®µï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦é‡å¤
            seen_phases = []

            for r in range(len(rows)):
                # è·å–è¯¥è¡Œçº¯æ–‡æœ¬ï¼Œç”¨äºåˆ¤æ–­é˜¶æ®µ
                row_raw_text = "".join(list(dict.fromkeys([c.text.strip() for c in rows[r].cells])))
                
                # 1. è¯†åˆ«é˜¶æ®µåˆ‡æ¢
                if row_raw_text in ["è¯¾å‰", "è¯¾ä¸­", "è¯¾å", "å·©å›ºæ‹“å±•"]:
                    # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ï¼šå¦‚æœè¿™ä¸ªé˜¶æ®µåå’Œå½“å‰é˜¶æ®µä¸€æ ·ï¼Œè¯´æ˜æ˜¯è·¨é¡µé‡å¤è¡¨å¤´ï¼Œç›´æ¥å¿½ç•¥
                    if row_raw_text == current_phase:
                        continue 
                    
                    # è¿™æ˜¯ä¸€ä¸ªæ–°çš„é˜¶æ®µ
                    current_phase = row_raw_text
                    seen_phases.append(current_phase)
                    continue
                
                # 2. æ­£å¸¸æŠ“å–å¡«ç©ºç‚¹
                for c_idx, col_name in col_map.items():
                    target_cell = table.cell(r, c_idx)
                    
                    # æ’é™¤éç©ºæ ¼å­ã€æ’é™¤è¡¨å¤´æœ¬èº«
                    if not target_cell.text.strip() and target_cell.text.strip() != col_name:
                        if target_cell._tc not in processed_cell_ids:
                            # æ„é€ å”¯ä¸€ Keyï¼šé˜¶æ®µ > æ ‡é¢˜ > è¡Œå·
                            full_key = f"{current_phase} > {col_name}_è¡Œ{r}"
                            
                            structure.append({
                                'key_text': full_key,
                                'original_text': col_name,
                                'target_coords': (t_idx, r, c_idx),
                                'is_teaching_process': True
                            })
                            processed_cell_ids.add(target_cell._tc)
            continue

        # --- ç­–ç•¥ Bï¼šé€šç”¨ä¿¡æ¯è¡¨ ---
        for r in range(len(rows)):
            for c in range(len(table.columns)):
                cell = table.cell(r, c)
                text = cell.text.strip().replace("\n", "").replace(" ", "")
                
                if not text or is_instructional(text): continue
                if text in processed_keys and len(text) < 10: continue

                target = None
                if c + 1 < len(table.columns):
                    r_c = table.cell(r, c + 1)
                    if not r_c.text.strip(): target = (r, c + 1, r_c._tc)
                if not target and r + 1 < len(rows):
                    d_c = table.cell(r + 1, c)
                    if not d_c.text.strip(): target = (r + 1, c, d_c._tc)
                
                if target:
                    tr, tc, t_id = target
                    if t_id not in processed_cell_ids:
                        full_key = text
                        p_header = table.cell(r, 0).text.strip()
                        if p_header in ["å­¦æƒ…åˆ†æ", "æ•™å­¦ç›®æ ‡", "æ•™å­¦èµ„æº", "æ•™å­¦åæ€"]:
                            if p_header != text: full_key = f"{p_header} > {text}"

                        structure.append({
                            'key_text': full_key,
                            'original_text': text,
                            'target_coords': (t_idx, tr, tc),
                            'is_teaching_process': False
                        })
                        processed_cell_ids.add(t_id)
                        processed_keys.add(text)

    return structure

# --- Logic: Chunked Generation Engine (V16 Optimized) ---
def generate_deep_content_chunked(user_inputs, doc_keys, api_key, logger):
    """
    ã€V16 å·®å¼‚åŒ–ç”Ÿæˆå¼•æ“ã€‘
    1. Batch Size æå‡è‡³ 45ï¼Œå¤§å¹…å‡å°‘è¯·æ±‚æ¬¡æ•°ã€‚
    2. Prompt åŒºåˆ†å¯¹å¾…ï¼šå­¦æƒ…/ç›®æ ‡è¦è¯¦å®ï¼Œè¿‡ç¨‹è¦å¹²ç»ƒä¸”æ— ç¼–å·ã€‚
    """
    llm = ChatOpenAI(
        model="deepseek-chat", 
        temperature=0.7, # ç¨å¾®å›å‡æ¸©åº¦ï¼Œè®©é•¿æ–‡å†™å¾—æ›´å¥½
        base_url="https://api.deepseek.com",
        openai_api_key=api_key
    )
    
    all_keys = [item['key_text'] for item in doc_keys]
    
    # ã€ä¿®æ”¹ç‚¹ã€‘ï¼šå¢åŠ  Batch Size åˆ° 45ï¼Œå‡å°‘åˆ†ç»„æ•°é‡
    BATCH_SIZE = 45
    
    total_batches = math.ceil(len(all_keys) / BATCH_SIZE)
    final_mapping = {}
    
    logger.log(f"ä»»åŠ¡æ€»é‡: {len(all_keys)} ä¸ªå­—æ®µï¼Œåˆå¹¶ä¸º {total_batches} æ‰¹æ¬¡æé€Ÿç”Ÿæˆ...", "ğŸš€")
    
    progress_bar = st.progress(0)
    
    for i in range(total_batches):
        start_idx = i * BATCH_SIZE
        end_idx = start_idx + BATCH_SIZE
        current_batch_keys = all_keys[start_idx:end_idx]
        
        logger.log(f"æ­£åœ¨ç”Ÿæˆç¬¬ {i+1}/{total_batches} æ‰¹...", "â³")
        
        # --- æ ¸å¿ƒä¿®æ”¹ï¼šPrompt å·®å¼‚åŒ–çº¦æŸ ---
        system_prompt = """
ä½ æ˜¯ä¸€ä½é¡¶å°–çš„æ•™æ¡ˆè®¾è®¡ä¸“å®¶ã€‚è¯·æ ¹æ®è¯¾ç¨‹èƒŒæ™¯ï¼Œå¡«å†™æ•™æ¡ˆç©ºæ ¼ã€‚

## âš ï¸ æ ¸å¿ƒæŒ‡ä»¤ï¼šå·®å¼‚åŒ–å†™ä½œé£æ ¼ (Differentiated Style)

è¯·æ ¹æ® **Key çš„ç±»å‹** è‡ªåŠ¨åˆ‡æ¢å†™ä½œæ¨¡å¼ï¼š

### æ¨¡å¼ Aï¼šã€å­¦æƒ…åˆ†æã€‘ä¸ã€æ•™å­¦ç›®æ ‡ã€‘ç±»
-   **é€‚ç”¨ Key**ï¼šåŒ…å« "å­¦æƒ…"ã€"ç›®æ ‡"ã€"åŸºç¡€"ã€"åˆ†æ" çš„å­—æ®µã€‚
-   **è¦æ±‚**ï¼š**å†…å®¹è¯¦å®ã€å…·ä½“**ã€‚å¯ä»¥å†™ 100 å­—å·¦å³ï¼Œåˆ†ç‚¹é˜è¿°ï¼Œæ·±å…¥åˆ†æå­¦ç”Ÿç‰¹ç‚¹å’Œæ•™å­¦ç›®çš„ã€‚

### æ¨¡å¼ Bï¼šã€æ•™å­¦è¿‡ç¨‹ã€‘ç±» (è¡¨æ ¼å†…å®¹)
-   **é€‚ç”¨ Key**ï¼šåŒ…å« "è¯¾å‰"ã€"è¯¾ä¸­"ã€"è¯¾å"ã€"æ´»åŠ¨"ã€"å†…å®¹" çš„å­—æ®µã€‚
-   **è¦æ±‚**ï¼š**çŸ­å°ç²¾æ‚**ã€‚
-   **âŒ ä¸¥ç¦ä½¿ç”¨ç¼–å·**ï¼šç¦æ­¢ä½¿ç”¨ "1. 2. 3." æˆ– "- " åˆ—è¡¨ç¬¦å·ã€‚**ç›´æ¥å†™åŠ¨ä½œï¼**
-   **ç¤ºä¾‹**ï¼š
    -   âŒ é”™è¯¯ï¼š1. æ•™å¸ˆæ’­æ”¾è§†é¢‘ã€‚2. æé—®å­¦ç”Ÿã€‚
    -   âœ… æ­£ç¡®ï¼šæ’­æ”¾è¡Œä¸šåº”ç”¨è§†é¢‘ï¼Œæé—®å¼•å‘æ€è€ƒï¼Œå±•ç¤ºä»£ç è¿è¡Œæ•ˆæœã€‚

### æ¨¡å¼ Cï¼šã€æ€æ”¿ä¸è§£å†³æªæ–½ã€‘
-   **è¦æ±‚**ï¼šå¿…é¡»ç»“åˆå…·ä½“çŸ¥è¯†ç‚¹ï¼Œæ‹’ç»ç©ºè¯ã€‚

## æ ¼å¼é“å¾‹
-   è¾“å‡ºåˆæ³•çš„ JSONï¼š`{{ "Key": "Value" }}`
-   Key å¿…é¡»ç”¨åŒå¼•å·ã€‚
-   **ä¸¥ç¦**å°¾éƒ¨é€—å·ã€‚
"""
        
        human_template = """
ã€è¯¾ç¨‹èƒŒæ™¯ã€‘: {user_inputs_json}

ã€æœ¬æ¬¡éœ€å¡«å†™çš„ Keyã€‘: 
{batch_keys_json}

è¯·ä¸¥æ ¼æŒ‰ç…§â€œå·®å¼‚åŒ–é£æ ¼â€å¡«å……ä¸Šè¿° Keyã€‚
"""
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", human_template)
        ])
        
        chain = prompt | llm
        
        retry_count = 0
        success = False
        
        while retry_count < 2 and not success:
            try:
                response = chain.invoke({
                    "user_inputs_json": json.dumps(user_inputs, ensure_ascii=False),
                    "batch_keys_json": json.dumps(current_batch_keys, ensure_ascii=False)
                })
                
                batch_result = extract_json_safe(response.content)
                
                if batch_result:
                    final_mapping.update(batch_result)
                    success = True
                else:
                    logger.log(f"ç¬¬ {i+1} æ‰¹æ¬¡ JSON è§£æå¤±è´¥ï¼Œé‡è¯•ä¸­...", "âš ï¸")
                    retry_count += 1
                    
            except Exception as e:
                logger.log(f"API è¯·æ±‚å¤±è´¥: {e}ï¼Œå†·å´åé‡è¯•...", "âš ï¸")
                retry_count += 1
                time.sleep(1) 
        
        if not success:
            logger.log(f"ç¬¬ {i+1} æ‰¹æ¬¡å¤±è´¥ï¼Œå·²è·³è¿‡ã€‚", "âŒ")
        
        progress_bar.progress((i + 1) / total_batches)

    # ç¡¬é€»è¾‘è¡¥ä¸
    logger.log("ç”Ÿæˆå®Œæ¯•ï¼Œæ­£åœ¨æ•´åˆæ•°æ®...", "ğŸ§©")
    
    manual_overrides = {
        "æˆè¯¾æ—¶é—´": user_inputs.get("æ—¶é—´"),
        "æ•™æ¡ˆåºå· > æˆè¯¾æ—¶é—´": user_inputs.get("æ—¶é—´"),
        "æˆè¯¾åœ°ç‚¹": user_inputs.get("åœ°ç‚¹"),
        "æ•™æ¡ˆåºå· > æˆè¯¾åœ°ç‚¹": user_inputs.get("åœ°ç‚¹"),
        "æˆè¯¾ç­çº§": user_inputs.get("ç­çº§"),
        "æˆè¯¾å†…å®¹ > æˆè¯¾ç­çº§": user_inputs.get("ç­çº§"),
        "æ•™å¸ˆå§“å": user_inputs.get("æ•™å¸ˆå§“å")
    }
    
    for k, v in manual_overrides.items():
        if v:
            final_mapping[k] = v
            
    return final_mapping

# --- Main App ---

def main():
    st.markdown("## ğŸ¤– AI æ™ºèƒ½æ•™æ¡ˆç”Ÿæˆå™¨ (V16 Flagship)")
    
    # 0. Global Logger
    logger = ConsoleLogger()

    # 1. Sidebar Config
    with st.sidebar:
        st.header("âš™ï¸ 1. åŸºç¡€é…ç½®")
        api_key = st.text_input("DeepSeek API Key", type="password")
        
        st.header("ğŸ“ 2. è¯¾ç¨‹åŸºç¡€ä¿¡æ¯")
        
        col1, col2 = st.columns(2)
        serial_no = col1.text_input("æ•™æ¡ˆåºå·", "No. 01")
        time_val = col2.text_input("æˆè¯¾æ—¶é—´", "2024-03-20")

        dept = st.text_input("éƒ¨é—¨/é™¢ç³»", "ä¿¡æ¯å·¥ç¨‹å­¦é™¢")
        teacher = st.text_input("æ•™å¸ˆå§“å", "å¼ ä¸‰")
        
        course_type = st.selectbox("è¯¾ç¨‹æ€§è´¨ (AIå¯è¦†ç›–)", ["ç†è®ºè¯¾", "å®è·µè¯¾", "ç†å®ä¸€ä½“åŒ–", "ç ”è®¨è¯¾"])
        
        user_inputs = {
            "æ•™æ¡ˆåºå·": serial_no,
            "æ—¶é—´": time_val,
            "éƒ¨é—¨": dept,
            "æ•™å¸ˆå§“å": teacher,
            "è¯¾ç¨‹æ€§è´¨": course_type
        }

        with st.expander("ğŸ“š æ›´å¤šè¯¾ç¨‹ç»†èŠ‚ (é€‰å¡«)", expanded=False):
            user_inputs["è¯¾ç¨‹åç§°"] = st.text_input("è¯¾ç¨‹åç§°", "Python ç¨‹åºè®¾è®¡")
            user_inputs["ç­çº§"] = st.text_input("ç­çº§", "23çº§è®¡ç®—æœº1ç­")
            user_inputs["åœ°ç‚¹"] = st.text_input("æˆè¯¾åœ°ç‚¹", "A305")
            user_inputs["æˆè¯¾å­¦æ—¶"] = st.number_input("å­¦æ—¶", 1, 4, 2)
            user_inputs["æˆè¯¾å½¢å¼"] = st.selectbox("æˆè¯¾å½¢å¼", ["çº¿ä¸‹é¢æˆ", "çº¿ä¸Šç›´æ’­", "æ··åˆå¼æ•™å­¦"])
            user_inputs["ä½¿ç”¨æ•™æ"] = st.text_input("ä½¿ç”¨æ•™æ", "ã€ŠPythonç¼–ç¨‹ï¼šä»å…¥é—¨åˆ°å®è·µã€‹")
            user_inputs["è€ƒæ ¸æ–¹å¼"] = st.selectbox("è€ƒæ ¸æ–¹å¼", ["è€ƒæŸ¥", "è€ƒè¯•", "è¿‡ç¨‹åŒ–è€ƒæ ¸"])

        st.header("ğŸ§  3. æ ¸å¿ƒå†…å®¹è¾“å…¥")
        topic_outline = st.text_area("æœ¬èŠ‚è¯¾ä¸»é¢˜ & å¤§çº²", height=250, 
                                     placeholder="è¾“å…¥æœ¬èŠ‚è¯¾çš„ä¸»é¢˜ï¼Œä¾‹å¦‚ï¼š\nä¸»é¢˜ï¼šPython å¾ªç¯ç»“æ„\n1. while å¾ªç¯\n2. fo å¾ªç¯\n3. æ¡ˆä¾‹å®æˆ˜")
        user_inputs["è¯¾ç¨‹å¤§çº²"] = topic_outline

    # 2. Main Area
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  Word æ•™æ¡ˆæ¨¡æ¿ (.docx)", type=["docx"])

    if uploaded_file and st.button("ğŸš€ å¼€å§‹ç”Ÿæˆ", type="primary"):
        if not api_key:
            st.error("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ DeepSeek API Key")
            return
        
        if not topic_outline:
            st.warning("è¯·å¡«å†™ã€è¯¾ç¨‹ä¸»é¢˜ & å¤§çº²ã€‘ï¼Œå¦åˆ™ AI æ— æ³•ç”Ÿæˆå†…å®¹ã€‚")
            return

        # Step 1: Parse
        doc = Document(uploaded_file)
        structure = get_table_structure(doc, logger)
        
        if not structure:
            st.warning("æœªèƒ½è¯†åˆ«åˆ°è¡¨æ ¼ç»“æ„ã€‚è¯·ç¡®ä¿æ–‡æ¡£åŒ…å«æ ‡å‡†è¡¨æ ¼ã€‚")
            return

        # Step 2: Generate (V16)
        mapping = generate_deep_content_chunked(user_inputs, structure, api_key, logger)
        
        # Step 3: Fill
        if mapping:
            logger.log("æ­£åœ¨å°†å†…å®¹å†™å…¥æ–‡æ¡£...", "ğŸ’¾")
            fill_count = 0
            
            # Progress bar for filling
            my_bar = st.progress(0)
            total_items = len(structure)
            
            for i, item in enumerate(structure):
                key = item['key_text']
                target_coords = item['target_coords']
                original_text = item['original_text']
                
                content = mapping.get(key) or mapping.get(original_text)
                
                if content:
                    t_idx, r, c = target_coords
                    target_cell = doc.tables[t_idx].cell(r, c)
                    set_cell_text_preserving_style(target_cell, str(content))
                    fill_count += 1
                    if i % 10 == 0: 
                        logger.log(f"å·²å¡«å…¥: {key} -> {str(content)[:10]}...", "ğŸ“")
                
                my_bar.progress(min((i + 1) / total_items, 1.0))

            logger.log(f"ğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±å¡«å…… {fill_count} ä¸ªå­—æ®µã€‚", "âœ…")
            st.success(f"ç”ŸæˆæˆåŠŸï¼")

            buffer = BytesIO()
            doc.save(buffer)
            buffer.seek(0)
            
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„æ•™æ¡ˆ",
                data=buffer,
                file_name="generated_lesson_plan_v16.docx",
                mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
            )
    
if __name__ == "__main__":
    main()